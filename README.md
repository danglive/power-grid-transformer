# Q-Transformer Data Module

This document provides detailed information about the Q-Transformer data module, including the structure of the underlying `.npz` files, the architecture of the data processing module, and analysis of the dataset characteristics.

## Table of Contents
1. [Dataset Structure](#dataset-structure)
2. [Data Module Architecture](#data-module-architecture)
3. [Data Splitting Strategies](#data-splitting-strategies)
4. [Data Visualization and Analysis](#data-visualization-and-analysis)
5. [Usage Guide](#usage-guide)
6. [Common Issues and Solutions](#common-issues-and-solutions)

## Dataset Structure

The Q-Transformer model uses `.npz` files with a specific structure for training and evaluation. Each file contains multiple arrays representing observations, actions, and associated data.

### Key Components

The `.npz` files contain the following arrays:

| Array Name | Shape | Type | Description |
|------------|-------|------|-------------|
| `obs` | (N_samples, 3819) | float32 | Observations of the system state for each sample |
| `act_rho` | (N_samples, 50) | structured array | Action data with base64-encoded action strings and `rho_max` values |
| `act_vect` | (N_samples, 50, 2) | object | Action vectors containing base64-encoded action strings and d_act vectors |
| `soft_labels` | (N_samples, 50) | object | Soft labels represented as tuples of (base64-encoded action string, probability value) |
| `timestep` | (N_samples,) | datetime64 | Timestep values corresponding to each sample |
| `best_action` | (N_samples,) | string | Best action string for each sample |

### Detailed Description

#### 1. `obs` (Observations)
- Shape: (50376, 3819) in train_val.npz and (6614, 3819) in test.npz
- Type: float32
- Contains system state features for each sample
- Value range: [-303547.5625, 1064897728.0000]
- Feature mean range: [-45652.1602, 1065118144.0000]

#### 2. `act_rho` (Action Rho)
- Shape: (50376, 50) in train_val.npz
- Type: structured array with fields ('action', '<U73') and ('rho_max', '<f4')
- Contains action strings and associated rho_max values
- Rho range: [0.3343, 6.1498] with mean 1.1529 and standard deviation 0.2941

#### 3. `act_vect` (Action Vectors)
- Shape: (50376, 50, 2) in train_val.npz
- Type: object
- Each element is a tuple containing:
  - Base64-encoded action string
  - d_act vector (numpy array of shape (1152,)) with values in {-1, 0, 1}
  - These vectors represent specific actions in the system

#### 4. `soft_labels` (Soft Labels)
- Shape: (50376, 50) in train_val.npz
- Type: object
- Each element is a tuple with:
  - Base64-encoded action string
  - Probability value for the action
- Represents probability distribution over possible actions

#### 5. `timestep` (Timestep)
- Shape: (50376,) in train_val.npz
- Type: datetime64[us]
- Time range: 2021-01-04T07:45:00.000000 → 2023-12-22T11:30:00.000000 (train_val)
- Time range: 2024-05-16T13:35:00.000000 → 2024-12-31T23:50:00.000000 (test)

#### 6. `best_action` (Best Action)
- Shape: (50376,) in train_val.npz
- Type: string
- Contains the identifier for the best action for each sample

### Dataset Generation

The dataset was generated by first collecting `obs`, `act_rho`, and `timestep` data, then processing it to create `act_vect` and `soft_labels`:

1. `act_vect` is created by decoding the action strings from `act_rho` into action vectors
2. `soft_labels` is derived by converting `rho_max` values to probability distributions using softmax with temperature

## Data Module Architecture

The data processing module is designed with a layered architecture to handle the complex structure of the Q-Transformer data efficiently.

### Key Components

```
src/data/
├── base.py                  # Base classes and interfaces
├── qtransformer_data.py     # Dataset and datamodule implementations
├── enhanced_splitter.py     # Advanced data splitting strategies
├── splitters.py             # Basic data splitting strategies
├── utils.py                 # Utility functions for data processing
└── __init__.py              # Module exports
```

### Base Classes

- `BaseDataset`: Abstract base class for all datasets
- `BaseDataModule`: Abstract base class for all data modules
- `DataStats`: Class for tracking and storing dataset statistics

### Implementation Classes

- `QTransformerDataset`: Specialized dataset for Q-Transformer data
- `QTransformerDataModule`: Data module for managing train/val/test splits
- `VectorCache`: Thread-safe cache for storing preprocessed vectors

### Splitting Strategies

The module implements several splitting strategies for temporal data:

1. `RandomSplit`: Simple random splitting
2. `TemporalSplit`: Time-based splitting with newer samples in validation
3. `StratifiedSplit`: Maintains action distribution across splits
4. `StratifiedTemporalSplit`: Time-aware split per action category
5. `ShuffleWeeksSplit`: Week-based stratified split
6. `HardCutoffSplit`: Time-based split with a fixed cutoff point

## Data Splitting Strategies

The `EnhancedSplitManager` provides several strategies for splitting data:

### Random Split
Randomly divides data into train and validation sets regardless of time.

### Temporal Split
Sorts samples by time and takes the most recent samples for validation.

### Stratified Split
Ensures each action category is represented in both train and validation sets with the same distribution.

### Stratified Temporal Split
For each action category, takes the most recent samples for validation, ensuring temporal progression while maintaining category representation.

### Shuffle Weeks Split
Groups samples by week and randomly assigns entire weeks to either train or validation, maintaining temporal coherence within weeks.

### Hard Cutoff Split
Simple temporal split with a fixed cutoff date, suitable for simulating production scenarios.

## Data Visualization and Analysis

The module generates several visualizations to help understand the dataset:

### Observation Distribution
![Distribution of Feature Means](images/obs_means_histogram.png)
- Most features have means near 0
- A few features have extremely high values (10^9)

### Rho Value Distribution
![Distribution of Rho Values](images/rho_distribution.png)
- Centered around 1.0 with most values between 0.8-1.3
- Range: 0.33 to 6.15

### Soft Label Distribution
![Distribution of Soft Label Values](images/soft_label_distribution.png)
- Highly skewed distribution with most values very small (<0.05)
- Reflects that only a few actions have high probability

### Timestep Distribution
![Distribution of Timesteps](images/timestep_distribution.png)
- Data spans from 2021-01 to 2023-12
- Highest density in 2022-06 to 2022-09 and 2023-08 to 2023-09

### Split Summary
![Sample Counts by Split](images/split_summary.png)
- Train: 42,819 samples (85%)
- Validation: 7,556 samples (15%)
- Test: 6,614 samples (from separate file)

### Drift Metrics
- Jensen-Shannon Divergence: 0.0000 (no significant distribution shift)
- Unseen label rate: 0.00% (all labels in validation appear in training)

### Weekly Entropy
![Mean Soft Label Entropy by Week](images/weekly_entropy.png)
- Entropy of soft labels is stable over time
- Ranges from 4-5 bits with no clear trend

### Weekly JSD
![Weekly JSD from Training Distribution](images/weekly_jsd.png)
- Shows distribution shift over time
- Highest shifts in late 2022 (weeks 46-47)

## Usage Guide

### Basic Usage

```python
from src.data import QTransformerDataModule

# Load configuration
with open('config.json', 'r') as f:
    config = json.load(f)

# Create data module
data_module = QTransformerDataModule(config)
data_module.setup()

# Get data loaders
train_loader = data_module.get_train_dataloader()
val_loader = data_module.get_val_dataloader()
test_loader = data_module.get_test_dataloader()

# Get a batch of data
batch = next(iter(train_loader))
observations = batch['observations']  # Shape: [batch_size, 3819]
action_vectors = batch['action_vectors']  # Shape: [batch_size, 50, 1152]
rho_values = batch['rho_values']  # Shape: [batch_size, 50]
soft_labels = batch['soft_labels']  # Shape: [batch_size, 50]
```

### Configuration

Example `config.json` for the data module:

```json
{
  "dataset_dir": "./",
  "saved_models_dir": "save_model",
  "training_files": [
    "train_val.npz"
  ],
  "testing_files": ["test.npz"],
  "val_size": 0.15,
  "split_strategy": "temporal",
  "test_size": 0.0,
  "use_external_test_data": true,
  "device": "cuda:1",
  "save_to_cache": true,
  "vector_scaler": true,
  "cache_dir": "data_cache_vector"
}
```

## Common Issues and Solutions

### Issue: Inconsistency Between Split Report and Data Loaders
**Problem**: The split report may show "Test samples: 1" but the test loader has many more batches.
**Solution**: This happens because the test data is loaded from a separate file after the initial split. Set `test_size=0` in the configuration to avoid this confusion.

### Issue: Memory Issues with Large Datasets
**Problem**: Processing large datasets can lead to out-of-memory errors.
**Solution**: The `QTransformerDataset` implements efficient data loading with caching. Configure the cache size with the `cache_capacity` parameter.

### Issue: Slow Data Loading
**Problem**: Initial data loading can be slow, especially for large datasets.
**Solution**: Enable `save_to_cache` in the configuration to cache processed data for faster subsequent loading.

### Issue: Different Data Formats
**Problem**: The code may not handle all potential formats of `.npz` files.
**Solution**: The `QTransformerDataset` is designed to handle various data formats through automatic format detection. If you encounter issues, check the data structure and adapt the processing methods as needed.

## Q-Transformer Data Module Sample Output Analysis

This document provides an analysis of the sample output from running the Q-Transformer data module on the training and test datasets.

### Sample Run Output Analysis

Below is an analysis of the output logs from processing the Q-Transformer datasets:

```
2025-04-16 22:32:46,834 - src.data - INFO - Loaded Q-Transformer data module with 23 components
2025-04-16 22:32:46,836 - test_data_module - INFO - Checking training file: train_val.npz - exists: True
2025-04-16 22:32:46,837 - test_data_module - INFO - Checking test file: test.npz - exists: True
```

The data module successfully loaded with 23 components, and both the training file (`train_val.npz`) and test file (`test.npz`) were found.

#### Data Structure Analysis

```
2025-04-16 22:33:02,931 - src.data.utils - INFO - Loaded train_val.npz in 16.09 seconds
2025-04-16 22:33:02,934 - src.data.utils - INFO - Found keys: ['obs', 'best_action', 'timestep', 'act_rho', 'soft_labels', 'act_vect']
2025-04-16 22:33:02,935 - src.data.utils - INFO -   obs: (50376, 3819), float32
2025-04-16 22:33:02,936 - src.data.utils - INFO -   best_action: (50376,), <U72
2025-04-16 22:33:02,936 - src.data.utils - INFO -   timestep: (50376,), datetime64[us]
2025-04-16 22:33:02,937 - src.data.utils - INFO -   act_rho: (50376, 50), [('action', '<U73'), ('rho_max', '<f4')]
2025-04-16 22:33:02,938 - src.data.utils - INFO -   soft_labels: (50376, 50), object
2025-04-16 22:33:02,939 - src.data.utils - INFO -   act_vect: (50376, 50, 2), object
```

The training data (`train_val.npz`) contains:
- 50,376 samples
- 3,819 features per observation
- 50 actions per sample
- Each action has a corresponding rho_max value and action vector
- Timestamps are in microsecond precision
- Best action is stored as a string with max length 72 characters

#### Data Split

```
2025-04-16 22:33:20,620 - src.data.enhanced_splitter - INFO - Splitting 50376 samples with strategy: temporal
2025-04-16 22:33:23,837 - src.data.enhanced_splitter - INFO - === Split Summary ===
2025-04-16 22:33:23,840 - src.data.enhanced_splitter - INFO - Train samples: 42819
2025-04-16 22:33:23,841 - src.data.enhanced_splitter - INFO - Val samples:   7556
2025-04-16 22:33:23,842 - src.data.enhanced_splitter - INFO - Test samples:  1
2025-04-16 22:33:23,843 - src.data.enhanced_splitter - INFO - Train time: 2021-01-04T07:45:00.000000 → 2023-08-23T23:00:00.000000
2025-04-16 22:33:23,844 - src.data.enhanced_splitter - INFO - Val time:   2023-08-23T23:05:00.000000 → 2023-12-22T11:30:00.000000
2025-04-16 22:33:23,845 - src.data.enhanced_splitter - INFO - JSD Drift (train vs val label dist): 0.0000
2025-04-16 22:33:23,845 - src.data.enhanced_splitter - INFO - Rate of unseen labels in val:       0.00%
2025-04-16 22:33:23,846 - src.data.enhanced_splitter - INFO - ⚠️  100.00% of val samples are from future relative to train
2025-04-16 22:33:23,847 - src.data.enhanced_splitter - INFO -    Future val time range: 2023-08-23T23:05:00.000000 → 2023-12-22T11:30:00.000000
```

The data was split using a temporal strategy:
- Train: 42,819 samples (85%)
- Validation: 7,556 samples (15%)
- Test: 1 sample (from the internal split - not the main test data)

**Key Insights:**
1. The validation set is entirely from the future relative to the training set, which is ideal for power grid prediction tasks
2. No distribution drift detected (JSD = 0.0) between train and validation labels
3. All labels in validation are also seen in the training set (unseen rate = 0.0%)
4. The data spans from January 2021 to December 2023

#### External Test Data

```
2025-04-16 22:33:28,843 - src.data.qtransformer_data - INFO - External test dataset contains 6614 samples
2025-04-16 22:33:28,847 - src.data.qtransformer_data - INFO - Test time range: 2024-05-16T13:35:00.000000 → 2024-12-31T23:50:00.000000
```

The external test data (`test.npz`) contains:
- 6,614 samples
- Time range: May 2024 to December 2024
- This test set is completely separate and represents future data beyond the training and validation sets

#### Dataset Statistics

```
2025-04-16 22:33:35,825 - src.data.base - INFO - Statistics computation completed in 6.66 seconds
2025-04-16 22:33:35,828 - src.data.base - INFO - Dataset Statistics:
2025-04-16 22:33:35,829 - src.data.base - INFO -   Number of samples: 50375
2025-04-16 22:33:35,830 - src.data.base - INFO -   Observation shape: torch.Size([3819])
2025-04-16 22:33:35,831 - src.data.base - INFO -   Action dimension: 1152
2025-04-16 22:33:35,832 - src.data.base - INFO -   Actions per sample: 50
2025-04-16 22:33:35,833 - src.data.base - INFO -   Feature range: [-34295.1016, 22695.4355]
2025-04-16 22:33:35,833 - src.data.base - INFO -   Feature mean range: [-34298.6211, 22690.6602]
2025-04-16 22:33:35,834 - src.data.base - INFO -   Rho range: [0.3343, 6.1498]
2025-04-16 22:33:35,835 - src.data.base - INFO -   Rho mean/std: 1.1529/0.2941
```

Key statistics about the dataset:
- Observation features range from -34,295 to 22,695
- Action vectors are 1,152-dimensional
- Rho values range from 0.33 to 6.15, with a mean of 1.15
- A rho value > 1.0 typically indicates overload conditions in power grid systems

#### Data Loaders and Batches

```
2025-04-16 22:33:35,842 - test_data_module - INFO - Train loader: 335 batches
2025-04-16 22:33:35,843 - test_data_module - INFO - Validation loader: 60 batches
2025-04-16 22:33:35,844 - test_data_module - INFO - Test loader: 52 batches
2025-04-16 22:33:37,607 - test_data_module - INFO - Observations shape: torch.Size([128, 3819])
2025-04-16 22:33:37,608 - test_data_module - INFO - Action vectors shape: torch.Size([128, 50, 1152])
2025-04-16 22:33:37,609 - test_data_module - INFO - Rho values shape: torch.Size([128, 50])
2025-04-16 22:33:37,612 - test_data_module - INFO - Soft labels shape: torch.Size([128, 50])
```

Data loader information:
- Batch size: 128 samples per batch (derived from shapes)
- Train: 335 batches (approx. 42,880 samples)
- Validation: 60 batches (approx. 7,680 samples)
- Test: 52 batches (approx. 6,656 samples)
- Each batch contains observations, action vectors, rho values, and soft labels

### Visualizations Analysis

#### Feature Distribution
The observation features have a wide range of values with most features concentrated near zero. This suggests that feature scaling (normalization or standardization) would be beneficial before training.

#### Rho Value Distribution
The majority of rho values are concentrated around 1.0, which is a critical threshold in power systems:
- Values < 1.0: System is operating within capacity
- Values > 1.0: System is in overload condition

The distribution shows that most samples represent normal operating conditions, with some samples showing overload situations (up to 6.15).

#### Soft Label Distribution
The soft labels are highly skewed toward very small values, indicating that:
- Most actions have very low probability in any given state
- Only a few actions are considered viable in each situation
- The model needs to be able to distinguish between many low-probability actions

#### Temporal Distribution
The data is not evenly distributed over time, with certain periods having more samples. This may indicate:
- Seasonal patterns in power grid operations
- Specific collection campaigns or incidents
- Potential bias toward certain time periods

### Key Observations

1. **Temporal Coherence**: The strict temporal split ensures a realistic evaluation scenario where the model is tested on future data.

2. **No Significant Label Drift**: Despite the temporal separation, there's minimal distribution shift in the action space, suggesting stability in the system over time.

3. **Future Test Set**: The external test set is from 2024, providing a completely out-of-sample evaluation dataset for final model assessment.

4. **Caching Efficiency**: The action and soft label caching shows perfect efficiency, with all 50 unique actions being cached, significantly speeding up data loading.

5. **Balanced Split Ratio**: The 85%/15% train/validation split provides sufficient data for both training and validation while maintaining temporal coherence.

This analysis confirms that the Q-Transformer data module is correctly processing and splitting the power grid data, with special attention to temporal aspects critical for forecasting applications.